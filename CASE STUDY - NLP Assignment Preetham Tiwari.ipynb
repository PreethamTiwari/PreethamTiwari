{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "540aca01",
   "metadata": {},
   "source": [
    "# Problem Statement:\n",
    "After understanding the syntax of your text document, now, you need to extract features from the text\n",
    "document using various methods like bag-of-words, CountVectorizer, TermFrequency–Inverse Document\n",
    "Frequency (Tf–Idf).\n",
    "Assignment for Bag-of-words\n",
    "1. Perform the following tasks using bag-of-words in Python:\n",
    "a) Create a function named ‘tokenized_text ()’that takes ‘sentence’ as its argument and performs\n",
    "word tokenization and removes all stopwords\n",
    "b) Create a function named ‘sorted_token ()’ that takes ‘sentence’ as its argument and removes\n",
    "the duplicate word tokens and returns a sorted list of word tokens\n",
    "c) Create a function named ‘bag_of_word ()’ that takes ‘sentence’ and ‘word’ as its arguments,\n",
    "calculates the frequency word count of word tokens, and returns a NumPy array of word tokens\n",
    "d) Create a bag-of-words model on the following sentences using the three functions defined\n",
    "above:\n",
    " Joe went to the store\n",
    " Joe wants to buy a dining set\n",
    " Joe met John at the store\n",
    " Joe and John are best friends\n",
    "e) Convert the sentences into vectors using bag-of-words\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d1236c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def tokenized_text(sentence):\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    cleaned_text = [w.lower() for w in words if w not in stop_words]\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "848ed50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_token(sentences):\n",
    "    words = []\n",
    "    for sentence in sentences:\n",
    "        w = extract_words(sentence)\n",
    "        words.extend(w)\n",
    "    words = sorted(list(set(words)))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3e03b7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(sentence, words):\n",
    "    sentence_words = extract_words(sentence)\n",
    "    bag = np.zeros(len(words))\n",
    "    for sw in sentence_words:\n",
    "        for i,word in enumerate(words):\n",
    "            if word == sw:\n",
    "                bag[i] += 1\n",
    "    return np.array(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "28da5669",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"Joe went to the store\",\n",
    "          \"Joe wants to buy a dining set\",\n",
    "          \"Joe met John at the store\",\n",
    "          \"Joe and John are best friends\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f9a9f641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['best', 'buy', 'dining', 'friends', 'joe', 'john', 'met', 'set', 'store', 'wants', 'went']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = sorted_token(corpus)\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca03988d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "87321cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words(\"Joe went to the store\", vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e266ef",
   "metadata": {},
   "source": [
    "# Assignment for CountVectorizer\n",
    "1. Perform the following tasks using CountVectorizer:\n",
    "a) Import ‘CountVectorizer’ from ‘sklearn.feature_extraction.text’\n",
    "b) Create a numpy array named ‘corpus’ that contains the following sentences:\n",
    " Joe went to the store\n",
    " Joe wants to buy a dining set\n",
    " Joe met John at the store\n",
    " Joe and John are best friends\n",
    "c) Use the ‘CountVectorizer’ class object to fit and transform the text present in ‘corpus’ and\n",
    "store the result in ‘bag_of_words’\n",
    "d) Print ‘bag_of_words’ as a numpy array\n",
    "e) Print all feature names of the above-created ‘CountVectorizer’ object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bbf78bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30355713",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus1 = np.array([\"Joe went to the store\",\n",
    "          \"Joe wants to buy a dining set\",\n",
    "          \"Joe met John at the store\",\n",
    "          \"Joe and John are best friends\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99b2a2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0],\n",
       "       [1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = CountVectorizer()\n",
    "bag_of_words = count.fit_transform(corpus1)\n",
    "bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65f0692c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = count.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "64e7884d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and',\n",
       " 'are',\n",
       " 'at',\n",
       " 'best',\n",
       " 'buy',\n",
       " 'dining',\n",
       " 'friends',\n",
       " 'joe',\n",
       " 'john',\n",
       " 'met',\n",
       " 'set',\n",
       " 'store',\n",
       " 'the',\n",
       " 'to',\n",
       " 'wants',\n",
       " 'went']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cfb9c542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>are</th>\n",
       "      <th>at</th>\n",
       "      <th>best</th>\n",
       "      <th>buy</th>\n",
       "      <th>dining</th>\n",
       "      <th>friends</th>\n",
       "      <th>joe</th>\n",
       "      <th>john</th>\n",
       "      <th>met</th>\n",
       "      <th>set</th>\n",
       "      <th>store</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>wants</th>\n",
       "      <th>went</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  are  at  best  buy  dining  friends  joe  john  met  set  store  the  \\\n",
       "0    0    0   0     0    0       0        0    1     0    0    0      1    1   \n",
       "1    0    0   0     0    1       1        0    1     0    0    1      0    0   \n",
       "2    0    0   1     0    0       0        0    1     1    1    0      1    1   \n",
       "3    1    1   0     1    0       0        1    1     1    0    0      0    0   \n",
       "\n",
       "   to  wants  went  \n",
       "0   1      0     1  \n",
       "1   1      1     0  \n",
       "2   0      0     0  \n",
       "3   0      0     0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(bag_of_words.toarray(),columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b32325",
   "metadata": {},
   "source": [
    "# Assignment for Term Frequency–Inverse Document Frequency\n",
    "1. Do the following operations:\n",
    "a) Import ‘TfidfVectorizer’ from ‘sklearn.feature_extraction.text’\n",
    "b) Create a numpy array named ‘corpus’ that contains the following sentences:\n",
    " Joe went to the store\n",
    " Joe wants to buy a dining set\n",
    " Joe met John at the store\n",
    " Joe and John are best friends\n",
    "c) Use the ‘TfidfVectorizer’ class to create an object to fit and transform the text present in\n",
    "‘corpus’ created above and store the result in ‘bag_of_words’\n",
    "g) Print ‘bag_of_words’ as a numpy array\n",
    "h) Print all feature names of the above-created ‘TfidfVectorizer’ object\n",
    "i) Print the ‘bag_of_words’ array as a pandas data frame with column names as feature names# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "04f7bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b5ee8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus2 = np.array([\"Joe went to the store\",\n",
    "          \"Joe wants to buy a dining set\",\n",
    "          \"Joe met John at the store\",\n",
    "          \"Joe and John are best friends\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f6b0c6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "de4597f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagof_words = vectorizer.fit_transform(corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f5e604de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.29462843, 0.        , 0.        ,\n",
       "        0.        , 0.44513219, 0.44513219, 0.44513219, 0.        ,\n",
       "        0.56459374],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.45203489,\n",
       "        0.45203489, 0.        , 0.23589056, 0.        , 0.        ,\n",
       "        0.45203489, 0.        , 0.        , 0.3563895 , 0.45203489,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.49164562, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.25656108, 0.38761905, 0.49164562,\n",
       "        0.        , 0.38761905, 0.38761905, 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.45203489, 0.45203489, 0.        , 0.45203489, 0.        ,\n",
       "        0.        , 0.45203489, 0.23589056, 0.3563895 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e40100d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and',\n",
       " 'are',\n",
       " 'at',\n",
       " 'best',\n",
       " 'buy',\n",
       " 'dining',\n",
       " 'friends',\n",
       " 'joe',\n",
       " 'john',\n",
       " 'met',\n",
       " 'set',\n",
       " 'store',\n",
       " 'the',\n",
       " 'to',\n",
       " 'wants',\n",
       " 'went']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d0343af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>are</th>\n",
       "      <th>at</th>\n",
       "      <th>best</th>\n",
       "      <th>buy</th>\n",
       "      <th>dining</th>\n",
       "      <th>friends</th>\n",
       "      <th>joe</th>\n",
       "      <th>john</th>\n",
       "      <th>met</th>\n",
       "      <th>set</th>\n",
       "      <th>store</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>wants</th>\n",
       "      <th>went</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.445132</td>\n",
       "      <td>0.445132</td>\n",
       "      <td>0.445132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.564594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452035</td>\n",
       "      <td>0.452035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.356389</td>\n",
       "      <td>0.452035</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.491646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256561</td>\n",
       "      <td>0.387619</td>\n",
       "      <td>0.491646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.387619</td>\n",
       "      <td>0.387619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.452035</td>\n",
       "      <td>0.452035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452035</td>\n",
       "      <td>0.235891</td>\n",
       "      <td>0.356389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        and       are        at      best       buy    dining   friends  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.452035  0.452035  0.000000   \n",
       "2  0.000000  0.000000  0.491646  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.452035  0.452035  0.000000  0.452035  0.000000  0.000000  0.452035   \n",
       "\n",
       "        joe      john       met       set     store       the        to  \\\n",
       "0  0.294628  0.000000  0.000000  0.000000  0.445132  0.445132  0.445132   \n",
       "1  0.235891  0.000000  0.000000  0.452035  0.000000  0.000000  0.356389   \n",
       "2  0.256561  0.387619  0.491646  0.000000  0.387619  0.387619  0.000000   \n",
       "3  0.235891  0.356389  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      wants      went  \n",
       "0  0.000000  0.564594  \n",
       "1  0.452035  0.000000  \n",
       "2  0.000000  0.000000  \n",
       "3  0.000000  0.000000  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe1 = pd.DataFrame(bag_of_words.toarray(), columns =feature_names)\n",
    "dataframe1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063c8078",
   "metadata": {},
   "source": [
    "# END OF ASSIGNMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43062a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
